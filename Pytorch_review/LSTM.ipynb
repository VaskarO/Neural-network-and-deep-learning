{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamaters\n",
    "batch_size = 100\n",
    "sequence_len= 28\n",
    "input_len = 28\n",
    "num_layers = 2\n",
    "num_class = 10\n",
    "hidden_size = 128\n",
    "epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing datasets\n",
    "train_data = datasets.FashionMNIST(root= './datasets/fashion_mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.FashionMNIST(root= \"./datasets/fashion_mnist\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_len, hidden_size, num_class, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_len, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_class)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        hidden_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "        cell_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "        out,_ = self.lstm(X, (hidden_states, cell_states))\n",
    "        output = self.output_layer(out[:, -1,:])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(input_len, hidden_size, num_class, num_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "optimizer2 = optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs, model, train_dataloader, loss_function):\n",
    "    total_steps = len(train_dataloader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch, (image, labels) in enumerate(train_dataloader):\n",
    "            images = image.reshape(-1, sequence_len, input_len)\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = loss_function(output, labels)\n",
    "\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "\n",
    "            if(batch+1)%100 == 0:\n",
    "                print(f\"Epoch count: {epoch}, Batch: {batch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch count: 0, Batch: 100, Loss: 2.301945447921753\n",
      "Epoch count: 0, Batch: 200, Loss: 2.299060583114624\n",
      "Epoch count: 0, Batch: 300, Loss: 2.29500675201416\n",
      "Epoch count: 0, Batch: 400, Loss: 2.2909274101257324\n",
      "Epoch count: 0, Batch: 500, Loss: 2.2930355072021484\n",
      "Epoch count: 0, Batch: 600, Loss: 2.290353298187256\n",
      "Epoch count: 1, Batch: 100, Loss: 2.2860372066497803\n",
      "Epoch count: 1, Batch: 200, Loss: 2.285726547241211\n",
      "Epoch count: 1, Batch: 300, Loss: 2.276427984237671\n",
      "Epoch count: 1, Batch: 400, Loss: 2.2731900215148926\n",
      "Epoch count: 1, Batch: 500, Loss: 2.274792432785034\n",
      "Epoch count: 1, Batch: 600, Loss: 2.266252279281616\n",
      "Epoch count: 2, Batch: 100, Loss: 2.256728172302246\n",
      "Epoch count: 2, Batch: 200, Loss: 2.2575173377990723\n",
      "Epoch count: 2, Batch: 300, Loss: 2.235334873199463\n",
      "Epoch count: 2, Batch: 400, Loss: 2.2238519191741943\n",
      "Epoch count: 2, Batch: 500, Loss: 2.2220988273620605\n",
      "Epoch count: 2, Batch: 600, Loss: 2.204092025756836\n",
      "Epoch count: 3, Batch: 100, Loss: 2.168156623840332\n",
      "Epoch count: 3, Batch: 200, Loss: 2.1660678386688232\n",
      "Epoch count: 3, Batch: 300, Loss: 2.112868309020996\n",
      "Epoch count: 3, Batch: 400, Loss: 2.0517587661743164\n",
      "Epoch count: 3, Batch: 500, Loss: 2.024585008621216\n",
      "Epoch count: 3, Batch: 600, Loss: 2.039022445678711\n",
      "Epoch count: 4, Batch: 100, Loss: 1.9104958772659302\n",
      "Epoch count: 4, Batch: 200, Loss: 1.9476145505905151\n",
      "Epoch count: 4, Batch: 300, Loss: 1.8164019584655762\n",
      "Epoch count: 4, Batch: 400, Loss: 1.719389796257019\n",
      "Epoch count: 4, Batch: 500, Loss: 1.6625120639801025\n",
      "Epoch count: 4, Batch: 600, Loss: 1.6429537534713745\n"
     ]
    }
   ],
   "source": [
    "training(epochs, model, train_dataloader, loss_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch count: 0, Batch: 100, Loss: 1.0342955589294434\n",
      "Epoch count: 0, Batch: 200, Loss: 0.7790061235427856\n",
      "Epoch count: 0, Batch: 300, Loss: 0.5219201445579529\n",
      "Epoch count: 0, Batch: 400, Loss: 0.5313878059387207\n",
      "Epoch count: 0, Batch: 500, Loss: 0.6365305185317993\n",
      "Epoch count: 0, Batch: 600, Loss: 0.3915071189403534\n",
      "Epoch count: 1, Batch: 100, Loss: 0.3867504894733429\n",
      "Epoch count: 1, Batch: 200, Loss: 0.3667123317718506\n",
      "Epoch count: 1, Batch: 300, Loss: 0.3222603499889374\n",
      "Epoch count: 1, Batch: 400, Loss: 0.42798274755477905\n",
      "Epoch count: 1, Batch: 500, Loss: 0.46218881011009216\n",
      "Epoch count: 1, Batch: 600, Loss: 0.2788180708885193\n",
      "Epoch count: 2, Batch: 100, Loss: 0.3336666226387024\n",
      "Epoch count: 2, Batch: 200, Loss: 0.3066610097885132\n",
      "Epoch count: 2, Batch: 300, Loss: 0.35651057958602905\n",
      "Epoch count: 2, Batch: 400, Loss: 0.3164610266685486\n",
      "Epoch count: 2, Batch: 500, Loss: 0.45928364992141724\n",
      "Epoch count: 2, Batch: 600, Loss: 0.23383377492427826\n",
      "Epoch count: 3, Batch: 100, Loss: 0.309396892786026\n",
      "Epoch count: 3, Batch: 200, Loss: 0.34919047355651855\n",
      "Epoch count: 3, Batch: 300, Loss: 0.2538145184516907\n",
      "Epoch count: 3, Batch: 400, Loss: 0.3463127911090851\n",
      "Epoch count: 3, Batch: 500, Loss: 0.45324620604515076\n",
      "Epoch count: 3, Batch: 600, Loss: 0.2570454180240631\n",
      "Epoch count: 4, Batch: 100, Loss: 0.2515009939670563\n",
      "Epoch count: 4, Batch: 200, Loss: 0.3776665925979614\n",
      "Epoch count: 4, Batch: 300, Loss: 0.28653624653816223\n",
      "Epoch count: 4, Batch: 400, Loss: 0.38123756647109985\n",
      "Epoch count: 4, Batch: 500, Loss: 0.3780696988105774\n",
      "Epoch count: 4, Batch: 600, Loss: 0.2656450867652893\n"
     ]
    }
   ],
   "source": [
    "#with Adam optimizer\n",
    "training(epochs, model, train_dataloader, loss_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
