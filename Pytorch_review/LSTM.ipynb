{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamaters\n",
    "batch_size = 100\n",
    "sequence_len= 28\n",
    "input_len = 28\n",
    "num_layers = 2\n",
    "num_class = 10\n",
    "hidden_size = 128\n",
    "epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing datasets\n",
    "train_data = datasets.FashionMNIST(root= './datasets/fashion_mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.FashionMNIST(root= \"./datasets/fashion_mnist\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_len, hidden_size, num_class, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_len, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_class)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        hidden_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "        cell_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "        out,_ = self.lstm(X, (hidden_states, cell_states))\n",
    "        output = self.output_layer(out[:, -1,:])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model instance\n",
    "model = LSTM(input_len, hidden_size, num_class, num_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "#creating second optimizer for better model performance\n",
    "optimizer2 = optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the LSTM model\n",
    "def training(epochs, model, train_dataloader, loss_function):\n",
    "    total_steps = len(train_dataloader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch, (image, labels) in enumerate(train_dataloader):\n",
    "            images = image.reshape(-1, sequence_len, input_len)\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = loss_function(output, labels)\n",
    "\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "\n",
    "            if(batch+1)%100 == 0:\n",
    "                print(f\"Epoch count: {epoch}, Batch: {batch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch count: 0, Batch: 100, Loss: 2.301945447921753\n",
      "Epoch count: 0, Batch: 200, Loss: 2.299060583114624\n",
      "Epoch count: 0, Batch: 300, Loss: 2.29500675201416\n",
      "Epoch count: 0, Batch: 400, Loss: 2.2909274101257324\n",
      "Epoch count: 0, Batch: 500, Loss: 2.2930355072021484\n",
      "Epoch count: 0, Batch: 600, Loss: 2.290353298187256\n",
      "Epoch count: 1, Batch: 100, Loss: 2.2860372066497803\n",
      "Epoch count: 1, Batch: 200, Loss: 2.285726547241211\n",
      "Epoch count: 1, Batch: 300, Loss: 2.276427984237671\n",
      "Epoch count: 1, Batch: 400, Loss: 2.2731900215148926\n",
      "Epoch count: 1, Batch: 500, Loss: 2.274792432785034\n",
      "Epoch count: 1, Batch: 600, Loss: 2.266252279281616\n",
      "Epoch count: 2, Batch: 100, Loss: 2.256728172302246\n",
      "Epoch count: 2, Batch: 200, Loss: 2.2575173377990723\n",
      "Epoch count: 2, Batch: 300, Loss: 2.235334873199463\n",
      "Epoch count: 2, Batch: 400, Loss: 2.2238519191741943\n",
      "Epoch count: 2, Batch: 500, Loss: 2.2220988273620605\n",
      "Epoch count: 2, Batch: 600, Loss: 2.204092025756836\n",
      "Epoch count: 3, Batch: 100, Loss: 2.168156623840332\n",
      "Epoch count: 3, Batch: 200, Loss: 2.1660678386688232\n",
      "Epoch count: 3, Batch: 300, Loss: 2.112868309020996\n",
      "Epoch count: 3, Batch: 400, Loss: 2.0517587661743164\n",
      "Epoch count: 3, Batch: 500, Loss: 2.024585008621216\n",
      "Epoch count: 3, Batch: 600, Loss: 2.039022445678711\n",
      "Epoch count: 4, Batch: 100, Loss: 1.9104958772659302\n",
      "Epoch count: 4, Batch: 200, Loss: 1.9476145505905151\n",
      "Epoch count: 4, Batch: 300, Loss: 1.8164019584655762\n",
      "Epoch count: 4, Batch: 400, Loss: 1.719389796257019\n",
      "Epoch count: 4, Batch: 500, Loss: 1.6625120639801025\n",
      "Epoch count: 4, Batch: 600, Loss: 1.6429537534713745\n"
     ]
    }
   ],
   "source": [
    "#starting the training loop\n",
    "training(epochs, model, train_dataloader, loss_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch count: 0, Batch: 100, Loss: 1.0342955589294434\n",
      "Epoch count: 0, Batch: 200, Loss: 0.7790061235427856\n",
      "Epoch count: 0, Batch: 300, Loss: 0.5219201445579529\n",
      "Epoch count: 0, Batch: 400, Loss: 0.5313878059387207\n",
      "Epoch count: 0, Batch: 500, Loss: 0.6365305185317993\n",
      "Epoch count: 0, Batch: 600, Loss: 0.3915071189403534\n",
      "Epoch count: 1, Batch: 100, Loss: 0.3867504894733429\n",
      "Epoch count: 1, Batch: 200, Loss: 0.3667123317718506\n",
      "Epoch count: 1, Batch: 300, Loss: 0.3222603499889374\n",
      "Epoch count: 1, Batch: 400, Loss: 0.42798274755477905\n",
      "Epoch count: 1, Batch: 500, Loss: 0.46218881011009216\n",
      "Epoch count: 1, Batch: 600, Loss: 0.2788180708885193\n",
      "Epoch count: 2, Batch: 100, Loss: 0.3336666226387024\n",
      "Epoch count: 2, Batch: 200, Loss: 0.3066610097885132\n",
      "Epoch count: 2, Batch: 300, Loss: 0.35651057958602905\n",
      "Epoch count: 2, Batch: 400, Loss: 0.3164610266685486\n",
      "Epoch count: 2, Batch: 500, Loss: 0.45928364992141724\n",
      "Epoch count: 2, Batch: 600, Loss: 0.23383377492427826\n",
      "Epoch count: 3, Batch: 100, Loss: 0.309396892786026\n",
      "Epoch count: 3, Batch: 200, Loss: 0.34919047355651855\n",
      "Epoch count: 3, Batch: 300, Loss: 0.2538145184516907\n",
      "Epoch count: 3, Batch: 400, Loss: 0.3463127911090851\n",
      "Epoch count: 3, Batch: 500, Loss: 0.45324620604515076\n",
      "Epoch count: 3, Batch: 600, Loss: 0.2570454180240631\n",
      "Epoch count: 4, Batch: 100, Loss: 0.2515009939670563\n",
      "Epoch count: 4, Batch: 200, Loss: 0.3776665925979614\n",
      "Epoch count: 4, Batch: 300, Loss: 0.28653624653816223\n",
      "Epoch count: 4, Batch: 400, Loss: 0.38123756647109985\n",
      "Epoch count: 4, Batch: 500, Loss: 0.3780696988105774\n",
      "Epoch count: 4, Batch: 600, Loss: 0.2656450867652893\n"
     ]
    }
   ],
   "source": [
    "#with Adam optimizer\n",
    "training(epochs, model, train_dataloader, loss_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
       "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
       "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
       "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
       "        0, 1, 4, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model\n",
    "test_images, test_labels = next(iter(test_dataloader))\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output =  model(test_images.view(-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 8, 3, 4, 1, 2, 2, 8, 0, 2, 5, 7, 5,\n",
       "        1, 2, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 0, 1, 6, 9, 6, 7, 2, 1,\n",
       "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 4, 3, 7, 8, 7, 0,\n",
       "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 2, 5, 3, 6, 7, 1, 8,\n",
       "        0, 1, 4, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = torch.max(test_output, 1)[1]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction = 90.0%\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = sum([1 for i in range(100) if predict[i] == test_labels[i]])/100\n",
    "print(f'Correct prediction = {correct_prediction *100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.34, Average loss: 0.3203294937312603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88.34"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many test dataloader items were correctly classified \n",
    "def test_func(dataloader, model, loss_function, optimizer2):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss , correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X= X.reshape(-1,28,28)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Accuracy: {(100*correct)}, Average loss: {test_loss}\")\n",
    "    return 100*correct\n",
    "\n",
    "test_func(test_dataloader,model, loss_function, optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
